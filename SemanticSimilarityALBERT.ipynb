{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8d81393",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8d81393",
    "outputId": "d6aff3a4-4a9d-4724-9a80-7f46d9e581d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "AMYXNE3Xglby",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMYXNE3Xglby",
    "outputId": "57f6ba5c-9532-4d97-befb-13cdc31a5098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vxca-EvpGSfJ",
   "metadata": {
    "id": "vxca-EvpGSfJ"
   },
   "source": [
    "#Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f40dd7f6",
   "metadata": {
    "id": "f40dd7f6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bebb634",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bebb634",
    "outputId": "3785f4af-0684-4cd8-da6b-c61ef1288cf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-4c9201446b86>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_train = pd.read_csv('./drive/MyDrive/Mini-projects/MSRP/train.tsv', sep='\\t', error_bad_lines=False)\n",
      "Skipping line 102: expected 5 fields, saw 6\n",
      "Skipping line 656: expected 5 fields, saw 6\n",
      "Skipping line 867: expected 5 fields, saw 6\n",
      "Skipping line 880: expected 5 fields, saw 6\n",
      "Skipping line 980: expected 5 fields, saw 6\n",
      "Skipping line 1439: expected 5 fields, saw 6\n",
      "Skipping line 1473: expected 5 fields, saw 6\n",
      "Skipping line 1822: expected 5 fields, saw 6\n",
      "Skipping line 1952: expected 5 fields, saw 6\n",
      "Skipping line 2009: expected 5 fields, saw 6\n",
      "Skipping line 2230: expected 5 fields, saw 6\n",
      "Skipping line 2506: expected 5 fields, saw 6\n",
      "Skipping line 2523: expected 5 fields, saw 6\n",
      "Skipping line 2809: expected 5 fields, saw 6\n",
      "Skipping line 2887: expected 5 fields, saw 6\n",
      "Skipping line 2920: expected 5 fields, saw 6\n",
      "Skipping line 2944: expected 5 fields, saw 6\n",
      "Skipping line 3241: expected 5 fields, saw 6\n",
      "Skipping line 3358: expected 5 fields, saw 6\n",
      "Skipping line 3459: expected 5 fields, saw 6\n",
      "\n",
      "<ipython-input-41-4c9201446b86>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_test = pd.read_csv('./drive/MyDrive/Mini-projects/MSRP/test.tsv', sep='\\t', error_bad_lines=False)\n",
      "Skipping line 34: expected 5 fields, saw 6\n",
      "Skipping line 121: expected 5 fields, saw 6\n",
      "Skipping line 211: expected 5 fields, saw 6\n",
      "Skipping line 263: expected 5 fields, saw 6\n",
      "Skipping line 345: expected 5 fields, saw 6\n",
      "Skipping line 696: expected 5 fields, saw 6\n",
      "Skipping line 733: expected 5 fields, saw 6\n",
      "Skipping line 847: expected 5 fields, saw 6\n",
      "Skipping line 1392: expected 5 fields, saw 6\n",
      "Skipping line 1467: expected 5 fields, saw 6\n",
      "Skipping line 1551: expected 5 fields, saw 6\n",
      "\n",
      "<ipython-input-41-4c9201446b86>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_val = pd.read_csv('./drive/MyDrive/Mini-projects/MSRP/dev.tsv', sep='\\t', error_bad_lines=False)\n",
      "Skipping line 13: expected 5 fields, saw 6\n",
      "Skipping line 165: expected 5 fields, saw 6\n",
      "Skipping line 218: expected 5 fields, saw 6\n",
      "Skipping line 477: expected 5 fields, saw 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./drive/MyDrive/Mini-projects/MSRP/train.tsv', sep='\\t', error_bad_lines=False)\n",
    "df_test = pd.read_csv('./drive/MyDrive/Mini-projects/MSRP/test.tsv', sep='\\t', error_bad_lines=False)\n",
    "df_val = pd.read_csv('./drive/MyDrive/Mini-projects/MSRP/dev.tsv', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "702d2240",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "702d2240",
    "outputId": "90991631-82c3-44d4-e70b-3e4b5ba6bfee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1a51f427-3679-4d40-b6f3-6ffcf51796ea\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>1</td>\n",
       "      <td>1466168</td>\n",
       "      <td>1466246</td>\n",
       "      <td>During the flight, engineers misjudged the ext...</td>\n",
       "      <td>During the flight, engineers underestimated th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>0</td>\n",
       "      <td>2245085</td>\n",
       "      <td>2245118</td>\n",
       "      <td>The Web site is registered to Parson under his...</td>\n",
       "      <td>The t33kid.com site is registered to Parson at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>1</td>\n",
       "      <td>3237867</td>\n",
       "      <td>3237902</td>\n",
       "      <td>The woman, Mary Kathryn Miller, 55, was arrest...</td>\n",
       "      <td>Mary Kathryn Miller, 55, of 27 Devon Road, Dar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>0</td>\n",
       "      <td>2194711</td>\n",
       "      <td>2194792</td>\n",
       "      <td>The Hubble Space Telescope's newest picture of...</td>\n",
       "      <td>The pictures were taken late Tuesday and early...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>1</td>\n",
       "      <td>954526</td>\n",
       "      <td>954607</td>\n",
       "      <td>He is blocking them until the Air Force assign...</td>\n",
       "      <td>He is holding them up until the Air Force agre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3458 rows Ã— 5 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a51f427-3679-4d40-b6f3-6ffcf51796ea')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1a51f427-3679-4d40-b6f3-6ffcf51796ea button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1a51f427-3679-4d40-b6f3-6ffcf51796ea');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-94e8cf45-faae-4f89-a2ea-37c825726dff\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94e8cf45-faae-4f89-a2ea-37c825726dff')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-94e8cf45-faae-4f89-a2ea-37c825726dff button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      Quality    #1 ID    #2 ID  \\\n",
       "0           1   702876   702977   \n",
       "1           0  2108705  2108831   \n",
       "2           1  1330381  1330521   \n",
       "3           0  3344667  3344648   \n",
       "4           1  1236820  1236712   \n",
       "...       ...      ...      ...   \n",
       "3453        1  1466168  1466246   \n",
       "3454        0  2245085  2245118   \n",
       "3455        1  3237867  3237902   \n",
       "3456        0  2194711  2194792   \n",
       "3457        1   954526   954607   \n",
       "\n",
       "                                              #1 String  \\\n",
       "0     Amrozi accused his brother, whom he called \"th...   \n",
       "1     Yucaipa owned Dominick's before selling the ch...   \n",
       "2     They had published an advertisement on the Int...   \n",
       "3     Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4     The stock rose $2.11, or about 11 percent, to ...   \n",
       "...                                                 ...   \n",
       "3453  During the flight, engineers misjudged the ext...   \n",
       "3454  The Web site is registered to Parson under his...   \n",
       "3455  The woman, Mary Kathryn Miller, 55, was arrest...   \n",
       "3456  The Hubble Space Telescope's newest picture of...   \n",
       "3457  He is blocking them until the Air Force assign...   \n",
       "\n",
       "                                              #2 String  \n",
       "0     Referring to him as only \"the witness\", Amrozi...  \n",
       "1     Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2     On June 10, the ship's owners had published an...  \n",
       "3     Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4     PG&E Corp. shares jumped $1.63 or 8 percent to...  \n",
       "...                                                 ...  \n",
       "3453  During the flight, engineers underestimated th...  \n",
       "3454  The t33kid.com site is registered to Parson at...  \n",
       "3455  Mary Kathryn Miller, 55, of 27 Devon Road, Dar...  \n",
       "3456  The pictures were taken late Tuesday and early...  \n",
       "3457  He is holding them up until the Air Force agre...  \n",
       "\n",
       "[3458 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67e175be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67e175be",
    "outputId": "f22c968c-bb63-403d-b28f-892543f51f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples : 3458\n",
      "Total validation samples: 480\n",
      "Total test samples: 1639\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total train samples : {df_train.shape[0]}\")\n",
    "print(f\"Total validation samples: {df_val.shape[0]}\")\n",
    "print(f\"Total test samples: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ce35ddd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ce35ddd",
    "outputId": "c126946b-b2ba-4b0b-dc0c-c1566eb2ffbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target Distribution\n",
      "1    0.673511\n",
      "0    0.326489\n",
      "Name: Quality, dtype: float64\n",
      "Train Target Distribution\n",
      "1    0.691667\n",
      "0    0.308333\n",
      "Name: Quality, dtype: float64\n",
      "Train Target Distribution\n",
      "1    0.663819\n",
      "0    0.336181\n",
      "Name: Quality, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Target Distribution\")\n",
    "print(df_train['Quality'].value_counts(1))\n",
    "\n",
    "print(\"Train Target Distribution\")\n",
    "print(df_val['Quality'].value_counts(1))\n",
    "\n",
    "print(\"Train Target Distribution\")\n",
    "print(df_test['Quality'].value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f923ea2",
   "metadata": {
    "id": "0f923ea2"
   },
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(df_train.Quality, num_classes=2)\n",
    "\n",
    "y_val = tf.keras.utils.to_categorical(df_val.Quality, num_classes=2)\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(df_test.Quality, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "SOg23pHtD1Qe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOg23pHtD1Qe",
    "outputId": "237fe357-2321-44b1-d44a-96d980ce6da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c50362ee",
   "metadata": {
    "id": "c50362ee"
   },
   "outputs": [],
   "source": [
    "max_length = 256  # maximum length of the tokenized input sentence pair : if greater than \"maxlen\", the input is truncated and else if smaller, the input is padded\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57abd137",
   "metadata": {
    "id": "57abd137"
   },
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Generates batches of data.\n",
    "\n",
    "    Args:\n",
    "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
    "        labels: Array of labels.\n",
    "        batch_size: Integer batch size.\n",
    "        shuffle: boolean, whether to shuffle the data.\n",
    "        include_targets: boolean, whether to incude the labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
    "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
    "         if `include_targets=False`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        include_targets=True,\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        # Load our BERT Tokenizer to encode the text.\n",
    "        # We will use base-base-uncased pretrained model.\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "            \"albert-base-v2\", do_lower_case=True\n",
    "        )\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
    "        # encoded together and separated by [SEP] token.\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence_pairs.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        # Convert batch of encoded features to numpy array.\n",
    "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
    "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
    "\n",
    "        # Set to true if data generator is used for training/validation.\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids, attention_masks, token_type_ids]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I0hwsEhtGZRW",
   "metadata": {
    "id": "I0hwsEhtGZRW"
   },
   "source": [
    "#Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebPsyz63u5AH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebPsyz63u5AH",
    "outputId": "8a2d80f9-e50c-4421-ba2f-20a662d4a2ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFAlbertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_albert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " albert (TFAlbertMainLayer)  multiple                  11683584  \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11685122 (44.58 MB)\n",
      "Trainable params: 11685122 (44.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAlbertForSequenceClassification\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "model_name = \"albert-base-v2\"\n",
    "model = TFAlbertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "#tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set up optimizer\n",
    "learning_rate = 2e-05\n",
    "optimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "num_epochs = 4\n",
    "# num_train_steps = len(df_train['Quality']) * num_epochs\n",
    "# decay_schedule = PolynomialDecay(initial_learning_rate=learning_rate, end_learning_rate=0, decay_steps=num_train_steps)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d730a3d0",
   "metadata": {
    "id": "d730a3d0"
   },
   "outputs": [],
   "source": [
    "train_data = BertSemanticDataGenerator(\n",
    "    df_train[[\"#1 String\", \"#2 String\"]].values.astype(\"str\"),\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_data = BertSemanticDataGenerator(\n",
    "    df_val[[\"#1 String\", \"#2 String\"]].values.astype(\"str\"),\n",
    "    y_val,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37f0910d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37f0910d",
    "outputId": "317dec26-0e5a-418a-cc25-6b11b2ce86bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - ETA: 0s - loss: 0.7650 - accuracy: 0.6557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "108/108 [==============================] - 225s 2s/step - loss: 0.7650 - accuracy: 0.6557 - val_loss: 0.5415 - val_accuracy: 0.7563\n",
      "Epoch 2/4\n",
      "108/108 [==============================] - 187s 2s/step - loss: 0.6518 - accuracy: 0.6797 - val_loss: 0.4913 - val_accuracy: 0.7521\n",
      "Epoch 3/4\n",
      "108/108 [==============================] - 197s 2s/step - loss: 0.5476 - accuracy: 0.7697 - val_loss: 0.4432 - val_accuracy: 0.7500\n",
      "Epoch 4/4\n",
      "108/108 [==============================] - 187s 2s/step - loss: 0.5002 - accuracy: 0.8163 - val_loss: 0.3061 - val_accuracy: 0.8854\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=4,\n",
    "    use_multiprocessing=True,\n",
    "    workers=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cuBKs05SGfR5",
   "metadata": {
    "id": "cuBKs05SGfR5"
   },
   "source": [
    "#Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6d26c69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6d26c69",
    "outputId": "fb20ad94-748c-4250-c4eb-aac2705bc158"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 34s 334ms/step - loss: 0.4437 - accuracy: 0.8248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4436703622341156, 0.8247548937797546]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = BertSemanticDataGenerator(\n",
    "    df_test[[\"#1 String\", \"#2 String\"]].values.astype(\"str\"),\n",
    "    y_test,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    ")\n",
    "model.evaluate(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "932cb367",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "932cb367",
    "outputId": "54ee45ee-b355-42cb-da0e-ab206c16b710"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 35s 625ms/step\n",
      "[TFSequenceClassifierOutput(loss=None, logits=array([[-0.26103374,  0.9959971 ],\n",
      "       [-0.12875836,  0.9697072 ],\n",
      "       [-0.42987508,  1.0616171 ],\n",
      "       ...,\n",
      "       [-0.27295467,  1.0452865 ],\n",
      "       [-0.20854439,  1.0621164 ],\n",
      "       [-0.07836369,  0.93327206]], dtype=float32), hidden_states=None, attentions=None)]\n"
     ]
    }
   ],
   "source": [
    "X_test = BertSemanticDataGenerator(\n",
    "    df_test[[\"#1 String\", \"#2 String\"]].values.astype(\"str\"),\n",
    "    labels=None, batch_size=len(df_test), shuffle=False, include_targets=False,\n",
    "    )\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "# Loop through the rows of X_test\n",
    "for i in range(len(X_test)):\n",
    "    # Make a prediction for the i-th row\n",
    "    prediction = model.predict(X_test[i])  # Assuming X_test is a DataFrame\n",
    "    y_pred.append(prediction)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11a0950d",
   "metadata": {
    "id": "11a0950d"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "# Convert y_pred to a NumPy array\n",
    "\n",
    "\n",
    "# Apply the threshold to obtain binary labels\n",
    "thresholded_array = (y_pred[0][0] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9bdcb26d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bdcb26d",
    "outputId": "997808bb-3d6e-442d-f24b-4eb33f7ccea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8267974500162502\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, thresholded_array.reshape(-1, 2), average='weighted')\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
